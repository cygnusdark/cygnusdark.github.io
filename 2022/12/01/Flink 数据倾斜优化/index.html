<!DOCTYPE html><html class="appearance-light" lang="zh-CN"><head><meta charset="UTF-8"><title>Flink 数据倾斜优化</title><meta name="description" content="数学是上帝用来书写宇宙的文字"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.ico"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/post.css"><link rel="stylesheet" href="/style/themes/highlight-theme-light.css"><link rel="stylesheet" href="/style/common/jquery.fancybox.min.css"><script src="/js/highlight.pack.js"></script><meta name="description" content="定义当进行聚合运算时（GroupBy&amp;#x2F;KeyBy + Agg），如果聚合所使用的key存在热点，则会导致数据倾斜。如统计某日各个省份的车流量，则负责运算北京、上海等一线城市的count subtask节点则会成为热点，处理数据的压力会比较大。
危害任务卡死keyBy 或 rebalance 下游的算子，如果单个 subtask 存在热点并完全卡死，会把整个 Flink 任务卡死。看如下示例：如下图所示，上游每个 Subtask 中会有 3 个 resultSubPartition，连接下游算子的 3 个 subtask。下游每个 subtask 会有 2 个 InputChannel，连接上游算子的 2 个 subtask。Local BufferPool为subtask中的ResultSubpa.."><meta name="generator" content="Hexo 6.3.0"></head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">Cygnus Dark's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><div class="is-full-height" id="postTopic"><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">Flink 数据倾斜优化</p><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">点击返回顶部</p></div></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">博客</a></h3><h3 class="is-inline-block"><a href="/about">个人简介</a></h3><h3 class="is-inline-block"><a href="/archives">文章</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">博客</a></h3><h3 class="is-inline-block"><a href="/about">个人简介</a></h3><h3 class="is-inline-block"><a href="/archives">文章</a></h3></header><main><main class="container is-max-widescreen content section post-page pt-4 px-4"><div class="columns is-flex-desktop is-justify-content-center is-flex-direction-row-reverse"><div class="column is-3 is-hidden-mobile"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89"><span class="toc-text">定义</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%B1%E5%AE%B3"><span class="toc-text">危害</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A1%E5%8D%A1%E6%AD%BB"><span class="toc-text">任务卡死</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Checkpoint%E6%97%B6%E9%97%B4%E5%8F%98%E9%95%BF"><span class="toc-text">Checkpoint时间变长</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#State%E5%8F%98%E5%A4%A7"><span class="toc-text">State变大</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95"><span class="toc-text">解决办法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5"><span class="toc-text">修改分区策略</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%AE%E6%A0%87"><span class="toc-text">目标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%89%8B%E6%AE%B5"><span class="toc-text">手段</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%A4%E9%98%B6%E6%AE%B5%E8%81%9A%E5%90%88"><span class="toc-text">两阶段聚合</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%AE%E6%A0%87-1"><span class="toc-text">目标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%89%8B%E6%AE%B5-1"><span class="toc-text">手段</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9sql"><span class="toc-text">修改sql</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Local-Global"><span class="toc-text">Local-Global</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Partial-Final"><span class="toc-text">Partial-Final</span></a></li></ol></li></ol></li></ol></li></ol></div><div class="column is-9"><header class="my-4"><a href="/tags/Flink"><i class="tag post-item-tag">Flink</i></a></header><h1 class="mt-0 mb-1 is-family-serif" id="postTitle">Flink 数据倾斜优化</h1><time class="has-text-grey" datetime="2022-12-01T00:00:00.000Z">2022-12-01</time><article class="mt-2 post-content"><h1 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h1><p>当进行聚合运算时（GroupBy&#x2F;KeyBy + Agg），如果聚合所使用的key存在热点，则会导致数据倾斜。如统计某日各个省份的车流量，则负责运算北京、上海等一线城市的count subtask节点则会成为热点，处理数据的压力会比较大。</p>
<h1 id="危害"><a href="#危害" class="headerlink" title="危害"></a>危害</h1><h2 id="任务卡死"><a href="#任务卡死" class="headerlink" title="任务卡死"></a>任务卡死</h2><p>keyBy 或 rebalance 下游的算子，如果单个 subtask 存在热点并完全卡死，会把整个 Flink 任务卡死。看如下示例：<br>如下图所示，上游每个 Subtask 中会有 3 个 resultSubPartition，连接下游算子的 3 个 subtask。下游每个 subtask 会有 2 个 InputChannel，连接上游算子的 2 个 subtask。Local BufferPool为subtask中的ResultSubpartition&#x2F;InputChannel所共用，在正常运行过程中如果没有反压，所有的 buffer pool 是用不完的。</p>
<p>一旦subtask B0变成热点，则会引起反压，依次产生如下问题：</p>
<ol>
<li>Subtask B0 内的 A0 和 A1 两个 InputChannel 会被占满；Subtask B0 公共的 BufferPool 中可申请到的空间也被占满</li>
<li>Subtask A0 和 A1 的 B0 ResultSubPartition 被占满；Subtask A0 和 A1 公共的 BufferPool 中可申请到的空间也被占满</li>
<li>如图2所示，Subtask A0 的主线程会从上游读取数据消费，按照数据的 KeyBy 规则，将数据发送到 B0、B1、B2 三个 ResultSubpartition 中；可以看到，如果 B0 这个ResultSubpartition占满了，且 B0 在公共的 Local BufferPool 中可申请到的空间也被占满。现在有一条数据被keyby后发往B0，但是现在 B0 这个ResultSubpartition 没有空间了，所以主线程就会卡在申请 buffer 上，直到可以再申请到 buffer</li>
</ol>
<p>Subtask A0 的主线程被卡住，则不会往下游的任何subtask发送数据了，如图1所示，下游的Subtask B1和Subtask B2不再接收新数据。整个任务处于瘫痪状态</p>
<h2 id="Checkpoint时间变长"><a href="#Checkpoint时间变长" class="headerlink" title="Checkpoint时间变长"></a>Checkpoint时间变长</h2><p>checkpoint barrier也是一种特殊的数据，如果整个任务中各个可用buffer变少，则checkpoint barrier的传输也会因为找不到可用buffer而降低速度；由于checkpoint barrier的对齐机制，会造成当前checkpoint的barrier迟迟无法对齐，进而超时。</p>
<h2 id="State变大"><a href="#State变大" class="headerlink" title="State变大"></a>State变大</h2><p>对于有两个以上输入管道的 Operator，存在checkpoint barrier对齐机制，接受到较快的输入管道的 barrier 后，它后面数据会被缓存起来但不处理，直到较慢的输入管道的 barrier 也到达，这些被缓存的数据会被放到state 里面，导致 checkpoint 变大。</p>
<h1 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h1><h2 id="修改分区策略"><a href="#修改分区策略" class="headerlink" title="修改分区策略"></a>修改分区策略</h2><h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3><p>让不需要shuffle的两个算子间进行shuffle，打乱数据，从而避免数据倾斜</p>
<h3 id="手段"><a href="#手段" class="headerlink" title="手段"></a>手段</h3><p>在Flink任务提交后，经常可以看到web ui中的一些算子之间采用的分区策略是forward，在该分区策略下很可能会存在数据倾斜现象。如以下情况：<br>某kafka topic统计每个省份的车次，针对每个省份都有一个partition，共计36个partition，同时设有36个source算子，36个flatmap算子。由于source和flatmap满足one-to-one关系，且并行度相同，则Flink默认会采用forward这个分区策略来关联source和flatmap这两个算子。<br>Flink默认设置forward分区策略有两个条件：</p>
<ol>
<li>两个算子满足one-to-one关系</li>
<li>两个算子并行度相同</li>
</ol>
<p>此时，北京和上海对应的flatmap算子必然会出现热点数据，由于source到flatmap算子之间并不需要有特定的对应关系，因此可以采用不同的分区策略来将数据打乱，让不同省份的车流数据落到所有的flatmap算子，消除数据倾斜。</p>
<p>因此，我们只需要破坏forward分区策略的条件即可</p>
<ol>
<li>修改两个算子的并行度</li>
<li>强行设定分区策略：<code>dataStream.rebalance();</code></li>
</ol>
<h2 id="两阶段聚合"><a href="#两阶段聚合" class="headerlink" title="两阶段聚合"></a>两阶段聚合</h2><p>所谓两阶段聚合，即在需要shuffle的两个算子之间，再加一层算子</p>
<h3 id="目标-1"><a href="#目标-1" class="headerlink" title="目标"></a>目标</h3><p>先进行一次聚合，减小算子2和算子3之间的数据量，减轻算子2和算子3之间的热点问题<br>新增新的shuffle，打散算子1和算子2之间的数据，减轻算子1和算子2之间的热点问题</p>
<h3 id="手段-1"><a href="#手段-1" class="headerlink" title="手段"></a>手段</h3><p>我们以sql的优化作为范例进行讲解，这样更加直观和简洁。DataStream API无非就是仿照sql的group by + agg模式，增加一层keyby + agg。</p>
<h4 id="修改sql"><a href="#修改sql" class="headerlink" title="修改sql"></a>修改sql</h4><p>有如下需求，按天统计每个类目的成交额</p>
<pre><code class="sql">SELECT 
    date_format(ctime, &#39;%Y%m%d&#39;) as cdate, -- 将数据从时间戳格式（2018-12-04 15:44:54），转换为date格式(20181204)
       category_id,
    sum(price) as category_gmv
FROM src
GROUP BY date_format(ctime, &#39;%Y%m%d&#39;), category_id; --按照天做聚合
</code></pre>
<p>以这个SQL为例，其数据流程图如下，一个小方块表示一条成交记录，不同颜色代表不同的category_id<br>Group By + Agg 模式中，SQL作业性能与数据分布非常相关，如果数据中存在数据倾斜，也就是某个key的数据异常的多，那么某个聚合节点就会成为瓶颈，作业就会有明显的反压及延时现象。<br>用两阶段聚合方法优化后的SQL如下：</p>
<pre><code class="sql">SELECT cdate,category_id,sum(category_gmv_p) as category_gmv
FROM(
    SELECT 
        date_format(ctime, &#39;%Y%m%d&#39;) as cdate, -- 将数据从时间戳格式（2018-12-04 15:44:54），转换为date格式(20181204)
           category_id,
        sum(price) as category_gmv_p
    FROM src
    GROUP BY category_id, mod(hash_code(FLOOR(RAND(1)*1000), 256),date_format(ctime, &#39;%Y%m%d&#39;); --按照天做聚合
)
GROUP BY cdate,category_id
</code></pre>
<p>SQL中做了将一个Group By+Agg拆称了两个，子查询里按照category_id和mod(hash_code(FLOOR(RAND(1)*1000), 256)分组，将同一个category_id上的数据打散成了256份，先做一层聚合。外层Group By+Agg，将子查询聚合后的结果再次做聚合。这样通过两层聚合的方式，即可大大缓解某聚合节点拥堵的现象。其数据流程图如下：<br>这种方法达到了两个优化目标，在日期的基础上再将数据分成256份，打散数据，减轻算子1和算子2之间的热点问题；在算子2进行了初步的sum聚合，减小了到达算子3的数据量，减轻了算子2和算子3之间的热点问题。 该方法通过取余的方式将数据进一步打散，另有给key添加随机数的方式进行打散</p>
<h4 id="Local-Global"><a href="#Local-Global" class="headerlink" title="Local-Global"></a>Local-Global</h4><p>LocalGlobal和PartialFinal其实都属于两阶段聚合，只不过封装了拆解逻辑，我们只需要对Flink SQL任务做简单的配置即可。</p>
<p>LocalGlobal优化可以用来解决聚合时的数据倾斜问题。其核心思想是，将聚合分为两个阶段执行，先在上游进行局部(本地&#x2F;Local)聚合，再在下游进行全局(Global)聚合，类似MapReduce的Combine + Reduce，即先进行一个本地Reduce，再进行全局Reduce。该方法，只完成了先进行一次聚合，减少数据量这个目标<br>以如下场景为例</p>
<pre><code class="sql">SELECT color, sum(id)
FROM T
GROUP BY color
</code></pre>
<p>开启LocalGlobal：</p>
<pre><code class="java">TableEnvironment tEnv = ...
Configuration configuration = tEnv.getConfig().getConfiguration();

// 要使用LocalGlobal优化，需要先开启MiniBatch 
configuration.setString(&quot;table.exec.mini-batch.enabled&quot;, &quot;true&quot;); 
configuration.setString(&quot;table.exec.mini-batch.allow-latency&quot;, &quot;5 s&quot;);
configuration.setString(&quot;table.exec.mini-batch.size&quot;, &quot;5000&quot;);

// 开启LocalGlobal
configuration.setString(&quot;table.optimizer.agg-phase-strategy&quot;, &quot;TWO_PHASE&quot;);
</code></pre>
<h4 id="Partial-Final"><a href="#Partial-Final" class="headerlink" title="Partial-Final"></a>Partial-Final</h4><p>LocalGlobal优化针对普通聚合（例如SUM、COUNT、MAX、MIN和AVG）有较好的效果，对于COUNT DISTINCT收效不明显，因为COUNT DISTINCT在Local聚合时，对于DISTINCT KEY的去重率不高，导致在Global节点仍然存在热点<br>如下场景，统计一天的UV</p>
<pre><code class="sql">SELECT day, COUNT(DISTINCT user_id)
FROM T
GROUP BY day
</code></pre>
<p>如果user_id比较稀疏，即便开启了LocalGlobal优化，收效也并不明显，因为COUNT DISTINCT在Local阶段时，去重率并不高，这就导致在Global阶段仍然存在热点问题。不满足第一条目标和第二条目标。<br>为了解决这一问题，需要将原始聚合拆分成两层聚合:</p>
<pre><code class="sql">SELECT day, SUM(cnt)
FROM (
    SELECT day, COUNT(DISTINCT user_id) as cnt
    FROM T
    GROUP BY day, MOD(HASH_CODE(user_id), 1024)
)
GROUP BY day
</code></pre>
<p>现在Blink Planner提供了PartialFinal功能，无需自己拆解sql，只要简单的配置即可，配置如下：</p>
<pre><code class="java">TableEnvironment tEnv = ...
Configuration configuration = tEnv.getConfig().getConfiguration();

// 开启MiniBatch 
configuration.setString(&quot;table.exec.mini-batch.enabled&quot;, &quot;true&quot;); 
configuration.setString(&quot;table.exec.mini-batch.allow-latency&quot;, &quot;5 s&quot;);
configuration.setString(&quot;table.exec.mini-batch.size&quot;, &quot;5000&quot;);

// 开启LocalGlobal
configuration.setString(&quot;table.optimizer.agg-phase-strategy&quot;, &quot;TWO_PHASE&quot;);

// 开启Split Distinct
configuration.setString(&quot;table.optimizer.distinct-agg.split.enabled&quot;, &quot;true&quot;);
</code></pre>
</article><section class="jump-container is-flex is-justify-content-space-between my-6"><!-- em is empty placeholder--><a class="button is-default" href="/2022/12/01/Flink%20%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7/" title="Flink 保证数据一致性"><i class="iconfont icon-prev mr-2 has-text-grey"></i><span class="has-text-weight-semibold">上一页: Flink 保证数据一致性</span></a><a class="button is-default" href="/2022/11/01/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/" title="多线程常见问题"><span class="has-text-weight-semibold">下一页: 多线程常见问题</span><i class="iconfont icon-next ml-2 has-text-grey"></i></a></section><article class="mt-6 comment-container"><script async repo="cygnusdark/cygnusdark" src="https://utteranc.es/client.js" issue-term="pathname" theme="preferred-color-scheme"></script></article></div></div></main></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/cygnusdark"><i class="iconfont icon-github"></i></a><!-- Ins--><!-- RSS--><!-- 知乎--><!-- 领英--><!-- 脸书--></section><p><span>Copyright ©</span><span> Cygnus Dark 2023</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by CygnusDark &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/cygnusdark">Theme by CygnusGarden&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/cygnusdark/cygnusgarden" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/js/jquery-3.6.1.min.js"></script><script src="/js/jquery-fancybox.min.js"></script><script src="/js/img_zoom.js"></script><script src="/js/post.js"></script></body></html>